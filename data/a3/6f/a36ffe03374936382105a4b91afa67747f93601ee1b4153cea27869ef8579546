[{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099590942","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1099590942","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1099590942,"node_id":"IC_kwDOCMmefs5Bim0e","user":{"login":"jhpoelen","id":1084872,"node_id":"MDQ6VXNlcjEwODQ4NzI=","avatar_url":"https://avatars.githubusercontent.com/u/1084872?v=4","gravatar_id":"","url":"https://api.github.com/users/jhpoelen","html_url":"https://github.com/jhpoelen","followers_url":"https://api.github.com/users/jhpoelen/followers","following_url":"https://api.github.com/users/jhpoelen/following{/other_user}","gists_url":"https://api.github.com/users/jhpoelen/gists{/gist_id}","starred_url":"https://api.github.com/users/jhpoelen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jhpoelen/subscriptions","organizations_url":"https://api.github.com/users/jhpoelen/orgs","repos_url":"https://api.github.com/users/jhpoelen/repos","events_url":"https://api.github.com/users/jhpoelen/events{/privacy}","received_events_url":"https://api.github.com/users/jhpoelen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-14T20:24:08Z","updated_at":"2022-04-14T20:24:08Z","body":"yep, there are some really big dwca out there. \r\n\r\nHalf of GBIF's occurrences sits in the single eBird dwca . \r\n\r\nI like to stream data from these big files using ```preston dwc-stream``` or ```unzip -p huge.zip somefile.txt``` . \r\n\r\nCurious to hear what you come up with or whether you have any remaining issues.","author_association":"MEMBER","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099590942/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099591925","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1099591925","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1099591925,"node_id":"IC_kwDOCMmefs5BinD1","user":{"login":"jhpoelen","id":1084872,"node_id":"MDQ6VXNlcjEwODQ4NzI=","avatar_url":"https://avatars.githubusercontent.com/u/1084872?v=4","gravatar_id":"","url":"https://api.github.com/users/jhpoelen","html_url":"https://github.com/jhpoelen","followers_url":"https://api.github.com/users/jhpoelen/followers","following_url":"https://api.github.com/users/jhpoelen/following{/other_user}","gists_url":"https://api.github.com/users/jhpoelen/gists{/gist_id}","starred_url":"https://api.github.com/users/jhpoelen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jhpoelen/subscriptions","organizations_url":"https://api.github.com/users/jhpoelen/orgs","repos_url":"https://api.github.com/users/jhpoelen/repos","events_url":"https://api.github.com/users/jhpoelen/events{/privacy}","received_events_url":"https://api.github.com/users/jhpoelen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-14T20:25:36Z","updated_at":"2022-04-14T20:35:46Z","body":"you can check the emls using\r\n\r\n```\r\n$ preston cat --remote https://deeplinker.bio --no-cache 'zip:hash://sha256/ec3ff57cb48d5c41b77b5d1075738b40f598a900e8be56e7645e5a24013dffc4!/eml.xml'\r\n<eml:eml xmlns:eml=\"eml://ecoinformatics.org/eml-2.1.1\"\r\n         xmlns:dc=\"http://purl.org/dc/terms/\"\r\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n         xsi:schemaLocation=\"eml://ecoinformatics.org/eml-2.1.1 http://rs.gbif.org/schema/eml-gbif-profile/1.0.2/eml.xsd\"\r\n         packageId=\"4fa7b334-ce0d-4e88-aaae-2e0c138d049e/v3\" system=\"http://gbif.org\" scope=\"system\"\r\n         xml:lang=\"eng\">\r\n\r\n<dataset>\r\n  <title xml:lang=\"eng\">EOD - eBird Observation Dataset</title>\r\n<creator>\r\n    <individualName>\r\n        <givenName>Tim</givenName>\r\n      <surName>Levatich</surName>\r\n    </individualName>\r\n    <organizationName>Cornell Lab of Ornithology</organizationName>\r\n    <positionName>Database Administrator</positionName>\r\n    <address>\r\n        <deliveryPoint>Information Science, 159 Sapsucker Woods Road</deliveryPoint>\r\n        <city>Ithaca</city>\r\n        <administrativeArea>NY</administrativeArea>\r\n        <postalCode>14850</postalCode>\r\n        <country>US</country>\r\n    </address>\r\n    <electronicMailAddress>tpl10@cornell.edu</electronicMailAddress>\r\n    <onlineUrl>http://ebird.org/</onlineUrl>\r\n</creator>\r\n<metadataProvider>\r\n    <individualName>\r\n        <givenName>Francisco</givenName>\r\n      <surName>Padilla</surName>\r\n    </individualName>\r\n    <organizationName>Cornell Lab of Ornithology</organizationName>\r\n    <positionName>Database Administrator</positionName>\r\n    <address>\r\n        <deliveryPoint>Information Science, 159 Sapsucker Woods Road</deliveryPoint>\r\n        <city>Ithaca</city>\r\n        <administrativeArea>NY</administrativeArea>\r\n        <postalCode>14850</postalCode>\r\n        <country>US</country>\r\n    </address>\r\n    <electronicMailAddress>fp235@cornell.edu</electronicMailAddress>\r\n    <onlineUrl>http://ebird.org/</onlineUrl>\r\n</metadataProvider>\r\n<pubDate>\r\n      \t2019-03-21\r\n</pubDate>\r\n<language>eng</language>\r\n<abstract>\r\n  <para>eBird is a collective enterprise that takes a novel approach to citizen science by developing cooperative partnerships among experts in a wide range of fields: population ecologists, conservation biologists, quantitative ecologists, statisticians, computer scientists, GIS and informatics specialists, application developers, and data administrators. Managed by the Cornell Lab of Ornithology eBirdâ€™s goal is to increase data quantity through participant recruitment and engagement globally, but also to quantify and control for data quality issues such as observer variability, imperfect detection of species, and both spatial and temporal bias in data collection. eBird data are openly available and used by a broad spectrum of students, teachers, scientists, NGOs, government agencies, land managers, and policy makers. The result is that eBird has become a major source of biodiversity data, increasing our knowledge of the dynamics of species distributions, and having a direct impact on the conservation of birds and their habitats.</para>\r\n</abstract>\r\n      <keywordSet>\r\n            <keyword>Occurrence</keyword>\r\n        <keywordThesaurus>GBIF Dataset Type Vocabulary: http://rs.gbif.org/vocabulary/gbif/dataset_type.xml</keywordThesaurus>\r\n      </keywordSet>\r\n      <keywordSet>\r\n            <keyword>Observation</keyword>\r\n        <keywordThesaurus>GBIF Dataset Subtype Vocabulary: http://rs.gbif.org/vocabulary/gbif/dataset_subtype.xml</keywordThesaurus>\r\n      </keywordSet>\r\n  <additionalInfo>\r\n    <para>Data release annually.  These data are made available through the Cornell Lab of Ornithology at Cornell University. No warranty either expressed or implied is made regarding the accuracy of these data.</para>\r\n  </additionalInfo>\r\n  <intellectualRights>\r\n    <para>\r\n        To the extent possible under law, the publisher has waived all rights to these data and has dedicated them to the\r\n        <ulink url=\"http://creativecommons.org/publicdomain/zero/1.0/legalcode\">\r\n          <citetitle>Public Domain (CC0 1.0)</citetitle>\r\n        </ulink>\r\n        .Users may copy, modify, distribute and use the work, including for commercial purposes, without restriction.\r\n      </para>\r\n  </intellectualRights>\r\n  <coverage>\r\n      <geographicCoverage>\r\n          <geographicDescription>Worldwide</geographicDescription>\r\n        <boundingCoordinates>\r\n          <westBoundingCoordinate>-180</westBoundingCoordinate>\r\n          <eastBoundingCoordinate>180</eastBoundingCoordinate>\r\n          <northBoundingCoordinate>90</northBoundingCoordinate>\r\n          <southBoundingCoordinate>-90</southBoundingCoordinate>\r\n        </boundingCoordinates>\r\n      </geographicCoverage>\r\n          <temporalCoverage>\r\n              <rangeOfDates>\r\n                  <beginDate>\r\n                    <calendarDate>1810-03-05</calendarDate>\r\n                  </beginDate>\r\n                <endDate>\r\n                  <calendarDate>2018-12-31</calendarDate>\r\n                </endDate>\r\n              </rangeOfDates>\r\n          </temporalCoverage>\r\n          <taxonomicCoverage>\r\n              <generalTaxonomicCoverage>taxonomic authority: The Clements Checklist of Birds, Sixth Edition</generalTaxonomicCoverage>\r\n              <taxonomicClassification>\r\n                  <taxonRankName>class</taxonRankName>\r\n                <taxonRankValue>Aves</taxonRankValue>\r\n                  <commonName>birds</commonName>\r\n              </taxonomicClassification>\r\n          </taxonomicCoverage>\r\n  </coverage>\r\n  <contact>\r\n    <individualName>\r\n        <givenName>Jeff</givenName>\r\n      <surName>Gerbracht</surName>\r\n    </individualName>\r\n    <organizationName>Cornell Lab of Ornithology</organizationName>\r\n    <positionName>Applications Leader for Information Science</positionName>\r\n    <address>\r\n        <deliveryPoint>Information Science, 159 Sapsucker Woods Road</deliveryPoint>\r\n        <city>Ithaca</city>\r\n        <administrativeArea>NY</administrativeArea>\r\n        <postalCode>14850</postalCode>\r\n        <country>US</country>\r\n    </address>\r\n    <electronicMailAddress>jag73@cornell.edu</electronicMailAddress>\r\n    <onlineUrl>http://ebird.org/</onlineUrl>\r\n  </contact>\r\n</dataset>\r\n  <additionalMetadata>\r\n    <metadata>\r\n      <gbif>\r\n          <dateStamp>2019-03-21T11:28:00.649-05:00</dateStamp>\r\n          <hierarchyLevel>dataset</hierarchyLevel>\r\n            <citation>2018. EOD - eBird Observation Dataset.</citation>\r\n      </gbif>\r\n    </metadata>\r\n  </additionalMetadata>\r\n</eml:eml>\r\n\r\n``` \r\n\r\nor similar.","author_association":"MEMBER","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099591925/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099598593","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1099598593","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1099598593,"node_id":"IC_kwDOCMmefs5BiosB","user":{"login":"pgasu","id":4916317,"node_id":"MDQ6VXNlcjQ5MTYzMTc=","avatar_url":"https://avatars.githubusercontent.com/u/4916317?v=4","gravatar_id":"","url":"https://api.github.com/users/pgasu","html_url":"https://github.com/pgasu","followers_url":"https://api.github.com/users/pgasu/followers","following_url":"https://api.github.com/users/pgasu/following{/other_user}","gists_url":"https://api.github.com/users/pgasu/gists{/gist_id}","starred_url":"https://api.github.com/users/pgasu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgasu/subscriptions","organizations_url":"https://api.github.com/users/pgasu/orgs","repos_url":"https://api.github.com/users/pgasu/repos","events_url":"https://api.github.com/users/pgasu/events{/privacy}","received_events_url":"https://api.github.com/users/pgasu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-14T20:35:16Z","updated_at":"2022-04-14T20:35:16Z","body":"I guess, I am going to run these files separately on compute nodes, and then let it take its own time. \r\nFor now I am trying to download all these datasets for the specific versions I require. I will share my progress and concern as I move along.  ","author_association":"NONE","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099598593/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099599635","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1099599635","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1099599635,"node_id":"IC_kwDOCMmefs5Bio8T","user":{"login":"jhpoelen","id":1084872,"node_id":"MDQ6VXNlcjEwODQ4NzI=","avatar_url":"https://avatars.githubusercontent.com/u/1084872?v=4","gravatar_id":"","url":"https://api.github.com/users/jhpoelen","html_url":"https://github.com/jhpoelen","followers_url":"https://api.github.com/users/jhpoelen/followers","following_url":"https://api.github.com/users/jhpoelen/following{/other_user}","gists_url":"https://api.github.com/users/jhpoelen/gists{/gist_id}","starred_url":"https://api.github.com/users/jhpoelen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jhpoelen/subscriptions","organizations_url":"https://api.github.com/users/jhpoelen/orgs","repos_url":"https://api.github.com/users/jhpoelen/repos","events_url":"https://api.github.com/users/jhpoelen/events{/privacy}","received_events_url":"https://api.github.com/users/jhpoelen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-14T20:36:43Z","updated_at":"2022-04-14T20:36:43Z","body":"ok. Why run them on a separate node? Do they fill-up your disks? \r\n\r\nNote that you can do --no-cache option to avoid accumulating all the stuff you've already processed.","author_association":"MEMBER","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099599635/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099600364","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1099600364","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1099600364,"node_id":"IC_kwDOCMmefs5BipHs","user":{"login":"jhpoelen","id":1084872,"node_id":"MDQ6VXNlcjEwODQ4NzI=","avatar_url":"https://avatars.githubusercontent.com/u/1084872?v=4","gravatar_id":"","url":"https://api.github.com/users/jhpoelen","html_url":"https://github.com/jhpoelen","followers_url":"https://api.github.com/users/jhpoelen/followers","following_url":"https://api.github.com/users/jhpoelen/following{/other_user}","gists_url":"https://api.github.com/users/jhpoelen/gists{/gist_id}","starred_url":"https://api.github.com/users/jhpoelen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jhpoelen/subscriptions","organizations_url":"https://api.github.com/users/jhpoelen/orgs","repos_url":"https://api.github.com/users/jhpoelen/repos","events_url":"https://api.github.com/users/jhpoelen/events{/privacy}","received_events_url":"https://api.github.com/users/jhpoelen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-14T20:37:45Z","updated_at":"2022-04-14T20:37:45Z","body":"Just holler if you have ideas for necessary functionality or when you have additional questions.\r\n\r\nVery curious about your outcomes!","author_association":"MEMBER","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099600364/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099894965","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1099894965","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1099894965,"node_id":"IC_kwDOCMmefs5BjxC1","user":{"login":"pgasu","id":4916317,"node_id":"MDQ6VXNlcjQ5MTYzMTc=","avatar_url":"https://avatars.githubusercontent.com/u/4916317?v=4","gravatar_id":"","url":"https://api.github.com/users/pgasu","html_url":"https://github.com/pgasu","followers_url":"https://api.github.com/users/pgasu/followers","following_url":"https://api.github.com/users/pgasu/following{/other_user}","gists_url":"https://api.github.com/users/pgasu/gists{/gist_id}","starred_url":"https://api.github.com/users/pgasu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgasu/subscriptions","organizations_url":"https://api.github.com/users/pgasu/orgs","repos_url":"https://api.github.com/users/pgasu/repos","events_url":"https://api.github.com/users/pgasu/events{/privacy}","received_events_url":"https://api.github.com/users/pgasu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-15T06:39:06Z","updated_at":"2022-04-15T06:39:35Z","body":"Well, normally Preston download the data locally, and I have received warning/error related to /tmp directory being full at some time. Also, reading through such big files would take long time - running it on a compute node doesn't make me worry about disconnection or other network errors.  ","author_association":"NONE","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1099894965/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1100108214","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1100108214","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1100108214,"node_id":"IC_kwDOCMmefs5BklG2","user":{"login":"jhpoelen","id":1084872,"node_id":"MDQ6VXNlcjEwODQ4NzI=","avatar_url":"https://avatars.githubusercontent.com/u/1084872?v=4","gravatar_id":"","url":"https://api.github.com/users/jhpoelen","html_url":"https://github.com/jhpoelen","followers_url":"https://api.github.com/users/jhpoelen/followers","following_url":"https://api.github.com/users/jhpoelen/following{/other_user}","gists_url":"https://api.github.com/users/jhpoelen/gists{/gist_id}","starred_url":"https://api.github.com/users/jhpoelen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jhpoelen/subscriptions","organizations_url":"https://api.github.com/users/jhpoelen/orgs","repos_url":"https://api.github.com/users/jhpoelen/repos","events_url":"https://api.github.com/users/jhpoelen/events{/privacy}","received_events_url":"https://api.github.com/users/jhpoelen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-15T13:24:26Z","updated_at":"2022-04-15T13:26:40Z","body":"@pgasu thanks for clarifying the reasons why you decided to process the bigger dwca elsewhere. I am sure you are not alone in having these hard disk and time constraints: I also have these issues, and have to take trips to the local Target to get some additional hard disk space every once in a while (see e.g., https://discourse.gbif.org/t/10-transactional-mechanisms-and-provenance/2667/52 )\r\n\r\nWould it help to have some kind of way to say: \"hey Preston, get me all this stuff, but only use up to 15GB of the local hard disk.\" ?\r\n\r\nAlso, I'd be curious to learn how long it would actually take to generate the >500M json records from the eBird dwca. What is the maximum time you'd want to spend on a single dwca? \r\n\r\n","author_association":"MEMBER","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1100108214/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1100142229","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1100142229","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1100142229,"node_id":"IC_kwDOCMmefs5BktaV","user":{"login":"PietrH","id":48065851,"node_id":"MDQ6VXNlcjQ4MDY1ODUx","avatar_url":"https://avatars.githubusercontent.com/u/48065851?v=4","gravatar_id":"","url":"https://api.github.com/users/PietrH","html_url":"https://github.com/PietrH","followers_url":"https://api.github.com/users/PietrH/followers","following_url":"https://api.github.com/users/PietrH/following{/other_user}","gists_url":"https://api.github.com/users/PietrH/gists{/gist_id}","starred_url":"https://api.github.com/users/PietrH/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/PietrH/subscriptions","organizations_url":"https://api.github.com/users/PietrH/orgs","repos_url":"https://api.github.com/users/PietrH/repos","events_url":"https://api.github.com/users/PietrH/events{/privacy}","received_events_url":"https://api.github.com/users/PietrH/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-15T14:28:24Z","updated_at":"2022-04-15T14:28:24Z","body":"I have some experience in working with occurrence data of this size, and while I can do my processing locally (or on the dev server), I've also used clusters/cloud in the past ([databricks on MS Azure](https://planetarycomputer.microsoft.com/), Flemish Supercomputer Centre, Google Colab).\r\n\r\nIf you are looking at distributed processing, or are having trouble with running out of memory you could use out of memory processing or things like Apache arrow. GBIF actually has (undocumented) support for Apache parquet exports: https://data-blog.gbif.org/post/apache-arrow-and-parquet/\r\n\r\nDepending on the hardware of course, I can parse/read a 150GB occurrence file in under 2 minutes, which about the time it takes me to wonder if I should start looking for a faster solution. I use data.table in R (https://github.com/Rdatatable/data.table) for out of memory efficient processing, a fork for [Python](https://towardsdatascience.com/an-overview-of-pythons-datatable-package-5d3a97394ee9) exists. For my personal big data needs I use Apache Spark. \r\n\r\nLoading a big occurrence file into Spark takes longer, but mounting [a very significant margin of all records on gbif](https://registry.opendata.aws/gbif/) doesn't take longer than I'm willing to wait. Somewhere between 5 and 20 minutes I'm guessing, probably depends a lot on your setup.\r\n\r\nIn my experience, uncompressing takes longer than the actual reading the of the file. [pigz ](https://linux.die.net/man/1/pigz)helps a lot in that regard. ","author_association":"NONE","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1100142229/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1100152529","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1100152529","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1100152529,"node_id":"IC_kwDOCMmefs5Bkv7R","user":{"login":"jhpoelen","id":1084872,"node_id":"MDQ6VXNlcjEwODQ4NzI=","avatar_url":"https://avatars.githubusercontent.com/u/1084872?v=4","gravatar_id":"","url":"https://api.github.com/users/jhpoelen","html_url":"https://github.com/jhpoelen","followers_url":"https://api.github.com/users/jhpoelen/followers","following_url":"https://api.github.com/users/jhpoelen/following{/other_user}","gists_url":"https://api.github.com/users/jhpoelen/gists{/gist_id}","starred_url":"https://api.github.com/users/jhpoelen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jhpoelen/subscriptions","organizations_url":"https://api.github.com/users/jhpoelen/orgs","repos_url":"https://api.github.com/users/jhpoelen/repos","events_url":"https://api.github.com/users/jhpoelen/events{/privacy}","received_events_url":"https://api.github.com/users/jhpoelen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-15T14:46:29Z","updated_at":"2022-04-15T14:47:03Z","body":"@PietrH thanks for sharing your experience.\r\n\r\nSome years ago, I also worked with the Apache Spark / HDFS / Kafka stack. . . and I found them impressive systems while also finding them to be tricky to tune and keep up and running - \r\n\r\nThessen AE, Poelen JH, Collins M, Hammock J. 20 GB in 10 minutes: a case for linking major biodiversity databases using an open socio-technical infrastructure and a pragmatic, cross-institutional collaboration. PeerJ Comput Sci. 2018 Sep 17;4:e164. doi: 10.7717/peerj-cs.164. PMID: 33816817; PMCID: PMC7924439. @diatomsRcool @jhammock \r\n\r\n```[...] The bottlenecks in processing for Hadoop File System and Apache Spark are the number of CPUs, amount of memory, and available storage space allocated to the computer cluster. Both HDFS and Spark are designed to scale horizontally by adding commodity servers (aka nodes) to increase the processing power, working memory, and storage space. Thus, this problem is immediately solvable. Internet bandwidth to transfer the data archives from Open Tree of Life, Wikidata, and GloBI does not scale and is not something that can be addressed solely within our research group. At the moment, it takes longer to download the Wikidata resource than it does to run the linking process discussed in this manuscript. [...]```\r\n\r\n\r\nThis experience system actually inspired many of the Preston features:\r\n\r\n1. migrating away from location-based to content-based identifiers to work around ```[...]  Internet bandwidth to transfer the data archives from Open Tree of Life, Wikidata, and GloBI does not scale [...]``` allowing for decentralized, offline-enabled, storage\r\n2. streaming directly from unaltered (zip) archives instead of having to unzip / preprocess them first\r\n3. easy to install offline-enabled command-line tools (e.g., [preston](https://github.com/bio-gupda/preston), [nomer](https://github.com/globalbioticinteractions/nomer))\r\n4. modular commands taking and producing streams (e.g., history, ls, cat, grep, dwc-stream) allow for parallelized workflows using ```xargs``` or ```parallel``` while keeping the door open for more complex solutions like apache kafka, apache spark etc.\r\n\r\nHopefully, discussions like these can help folks find the data and tools that work for best them. And, perhaps I get some inspiration for making existing tools a little more useful.\r\n\r\n","author_association":"MEMBER","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1100152529/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1100156103","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1100156103","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1100156103,"node_id":"IC_kwDOCMmefs5BkwzH","user":{"login":"PietrH","id":48065851,"node_id":"MDQ6VXNlcjQ4MDY1ODUx","avatar_url":"https://avatars.githubusercontent.com/u/48065851?v=4","gravatar_id":"","url":"https://api.github.com/users/PietrH","html_url":"https://github.com/PietrH","followers_url":"https://api.github.com/users/PietrH/followers","following_url":"https://api.github.com/users/PietrH/following{/other_user}","gists_url":"https://api.github.com/users/PietrH/gists{/gist_id}","starred_url":"https://api.github.com/users/PietrH/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/PietrH/subscriptions","organizations_url":"https://api.github.com/users/PietrH/orgs","repos_url":"https://api.github.com/users/PietrH/repos","events_url":"https://api.github.com/users/PietrH/events{/privacy}","received_events_url":"https://api.github.com/users/PietrH/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-15T14:53:08Z","updated_at":"2022-04-15T14:53:08Z","body":"I have certainly noticed some of these complications with Spark. Personally, depending on the task I'll process it completely locally using data.table, on a local spark instance or on a spark cluster somewhere in a datacenter. Spark and Arrow are certainly less approachable than a simple csv, and I want to stress that while maybe not optimal, handling 100GB+ text files locally using interpreted languages like Python and R is still within the capabilities of my laptop and the limits of my patience. Spark really shines in big table joins and optimizing complex filter operations (mapreduce I suppose).\r\n","author_association":"NONE","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1100156103/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1100168410","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1100168410","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1100168410,"node_id":"IC_kwDOCMmefs5Bkzza","user":{"login":"jhpoelen","id":1084872,"node_id":"MDQ6VXNlcjEwODQ4NzI=","avatar_url":"https://avatars.githubusercontent.com/u/1084872?v=4","gravatar_id":"","url":"https://api.github.com/users/jhpoelen","html_url":"https://github.com/jhpoelen","followers_url":"https://api.github.com/users/jhpoelen/followers","following_url":"https://api.github.com/users/jhpoelen/following{/other_user}","gists_url":"https://api.github.com/users/jhpoelen/gists{/gist_id}","starred_url":"https://api.github.com/users/jhpoelen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jhpoelen/subscriptions","organizations_url":"https://api.github.com/users/jhpoelen/orgs","repos_url":"https://api.github.com/users/jhpoelen/repos","events_url":"https://api.github.com/users/jhpoelen/events{/privacy}","received_events_url":"https://api.github.com/users/jhpoelen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-15T15:14:09Z","updated_at":"2022-04-15T15:14:09Z","body":"fyi @cboettig","author_association":"MEMBER","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1100168410/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1104105879","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1104105879","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1104105879,"node_id":"IC_kwDOCMmefs5Bz1GX","user":{"login":"pgasu","id":4916317,"node_id":"MDQ6VXNlcjQ5MTYzMTc=","avatar_url":"https://avatars.githubusercontent.com/u/4916317?v=4","gravatar_id":"","url":"https://api.github.com/users/pgasu","html_url":"https://github.com/pgasu","followers_url":"https://api.github.com/users/pgasu/followers","following_url":"https://api.github.com/users/pgasu/following{/other_user}","gists_url":"https://api.github.com/users/pgasu/gists{/gist_id}","starred_url":"https://api.github.com/users/pgasu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pgasu/subscriptions","organizations_url":"https://api.github.com/users/pgasu/orgs","repos_url":"https://api.github.com/users/pgasu/repos","events_url":"https://api.github.com/users/pgasu/events{/privacy}","received_events_url":"https://api.github.com/users/pgasu/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-04-20T16:00:38Z","updated_at":"2022-04-20T16:00:38Z","body":"> Would it help to have some kind of way to say: \"hey Preston, get me all this stuff, but only use up to 15GB of the local hard disk.\" ?\r\n\r\nI can see why this can be a really good feature for someone who doesn't have access to compute resources. If I have to work it locally on my machine, it would be very helpful to know the memory and disk space requirements, and restrict the required resources based on availability. This makes me curious about how 'Preston dwc-stream' works? It looks like it doesn't download the whole data, because my data folder still shows 96G, although I scanned through the complete version 38, including those large ~150G files. But I also noticed that it first scans through the whole data, and only then output the results, because it took several hours for reading/downloading the large eBird dwca, before it starts writing which took just few minutes. Does it keep the data in tmp folder or in memory? It would be nice to know what goes behind the scene - May be we can then parallelize dwc-stream process by splitting the file into multiple parts?\r\n\r\n> Also, I'd be curious to learn how long it would actually take to generate the >500M json records from the eBird dwca. What is the maximum time you'd want to spend on a single dwca?\r\n\r\nIt actually took 372 mins (~ 6 hrs) to read through the eBird dwca. I was so involved in the technical sides of things that I forgot that I am only interested in mammal data for the current project, and realized I really didn't need to go through eBird data. Anyways, it was fun exercise. Regarding how much time I would like to spend on a single dwca, I guess it's a matter of requirements of the project. In my case, I would wait even if it takes a day or two. I believe what bothers, in general, is the reliability of the process and the debugging turnaround time in large files. ","author_association":"NONE","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1104105879/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1222772743","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1222772743","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1222772743,"node_id":"IC_kwDOCMmefs5I4ggH","user":{"login":"jhpoelen","id":1084872,"node_id":"MDQ6VXNlcjEwODQ4NzI=","avatar_url":"https://avatars.githubusercontent.com/u/1084872?v=4","gravatar_id":"","url":"https://api.github.com/users/jhpoelen","html_url":"https://github.com/jhpoelen","followers_url":"https://api.github.com/users/jhpoelen/followers","following_url":"https://api.github.com/users/jhpoelen/following{/other_user}","gists_url":"https://api.github.com/users/jhpoelen/gists{/gist_id}","starred_url":"https://api.github.com/users/jhpoelen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jhpoelen/subscriptions","organizations_url":"https://api.github.com/users/jhpoelen/orgs","repos_url":"https://api.github.com/users/jhpoelen/repos","events_url":"https://api.github.com/users/jhpoelen/events{/privacy}","received_events_url":"https://api.github.com/users/jhpoelen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-08-22T18:44:06Z","updated_at":"2022-08-22T18:44:06Z","body":"@pgasu hey Prashant, please let me know if I addressed this issue re: suspiciously large DwC-A files in Person archive v. 38. \r\n\r\nAlso, I'd be curious to hear what method you ended up using, especially if you chose not to go the Preston route.\r\n\r\nHope all is well!","author_association":"MEMBER","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1222772743/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1222777636","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1222777636","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1222777636,"node_id":"IC_kwDOCMmefs5I4hsk","user":{"login":"jhpoelen","id":1084872,"node_id":"MDQ6VXNlcjEwODQ4NzI=","avatar_url":"https://avatars.githubusercontent.com/u/1084872?v=4","gravatar_id":"","url":"https://api.github.com/users/jhpoelen","html_url":"https://github.com/jhpoelen","followers_url":"https://api.github.com/users/jhpoelen/followers","following_url":"https://api.github.com/users/jhpoelen/following{/other_user}","gists_url":"https://api.github.com/users/jhpoelen/gists{/gist_id}","starred_url":"https://api.github.com/users/jhpoelen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jhpoelen/subscriptions","organizations_url":"https://api.github.com/users/jhpoelen/orgs","repos_url":"https://api.github.com/users/jhpoelen/repos","events_url":"https://api.github.com/users/jhpoelen/events{/privacy}","received_events_url":"https://api.github.com/users/jhpoelen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-08-22T18:49:10Z","updated_at":"2022-08-22T18:49:10Z","body":"Please feel free to comments / re-open if you have unresolved issues.\r\n\r\nfyi @n8upham ","author_association":"MEMBER","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1222777636/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1225001102","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1225001102","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1225001102,"node_id":"IC_kwDOCMmefs5JBAiO","user":{"login":"n8upham","id":12020947,"node_id":"MDQ6VXNlcjEyMDIwOTQ3","avatar_url":"https://avatars.githubusercontent.com/u/12020947?v=4","gravatar_id":"","url":"https://api.github.com/users/n8upham","html_url":"https://github.com/n8upham","followers_url":"https://api.github.com/users/n8upham/followers","following_url":"https://api.github.com/users/n8upham/following{/other_user}","gists_url":"https://api.github.com/users/n8upham/gists{/gist_id}","starred_url":"https://api.github.com/users/n8upham/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/n8upham/subscriptions","organizations_url":"https://api.github.com/users/n8upham/orgs","repos_url":"https://api.github.com/users/n8upham/repos","events_url":"https://api.github.com/users/n8upham/events{/privacy}","received_events_url":"https://api.github.com/users/n8upham/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-08-23T23:51:05Z","updated_at":"2022-08-23T23:51:05Z","body":"Thanks Jorrit -- @pgasu is re-visiting some aspects of this project in the next few days, so I can let you know if we have additional questions.","author_association":"NONE","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1225001102/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null},{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1231902310","html_url":"https://github.com/bio-guoda/preston/issues/163#issuecomment-1231902310","issue_url":"https://api.github.com/repos/bio-guoda/preston/issues/163","id":1231902310,"node_id":"IC_kwDOCMmefs5JbVZm","user":{"login":"jhpoelen","id":1084872,"node_id":"MDQ6VXNlcjEwODQ4NzI=","avatar_url":"https://avatars.githubusercontent.com/u/1084872?v=4","gravatar_id":"","url":"https://api.github.com/users/jhpoelen","html_url":"https://github.com/jhpoelen","followers_url":"https://api.github.com/users/jhpoelen/followers","following_url":"https://api.github.com/users/jhpoelen/following{/other_user}","gists_url":"https://api.github.com/users/jhpoelen/gists{/gist_id}","starred_url":"https://api.github.com/users/jhpoelen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jhpoelen/subscriptions","organizations_url":"https://api.github.com/users/jhpoelen/orgs","repos_url":"https://api.github.com/users/jhpoelen/repos","events_url":"https://api.github.com/users/jhpoelen/events{/privacy}","received_events_url":"https://api.github.com/users/jhpoelen/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2022-08-30T16:33:22Z","updated_at":"2022-08-30T16:33:22Z","body":"@n8upham thanks for responding. Assuming that you and @pgasu have no additional question at this point, so I am closing this issue. Happy to re-open if questions come up related to the topic of large dwca in Preston archives. ","author_association":"MEMBER","reactions":{"url":"https://api.github.com/repos/bio-guoda/preston/issues/comments/1231902310/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null}]